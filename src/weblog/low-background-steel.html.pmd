#lang pollen

◊(define-meta title "Low-Background Steel; Low-Silicon Text")
◊(define-meta date "2023-04-14")
◊(define-meta summary "Comparison of historical global changes to the latest AI revolution.")


# ◊(select-from-metas 'title (current-metas))
<time>◊(select-from-metas 'date (current-metas))</time>

This was a metaphor I saw recently somewhere on the internet.
Likely on Hacker News, my guilty pleasure.

## Low-background Steel

[Low-background steel](https://en.wikipedia.org/wiki/Low-background_steel) is steel that was produced before the advent of the nuclear bomb, and contains far less radioactive inclusions than contemporary steel.
This is not to say that modern steel contains a large amount of radiation.
Rather, if you're producing a very precise machine (say, a medical imaging device),
your goal is to minimize interference, and so you'll likely seek out materials that produce as little radiation as possible.

Why does steel contain this radiation?
The nuclear tests following the end of the second world war seeded the atmosphere with minuscule amounts of radiation.
Producing steel is a relatively simple reaction: Iron oxide is combined with carbon, usually, to produce iron and carbon dioxide.
In the process of this reduction, atmospheric gasses sneak in.

So where does one obtain low-background steel from?
The past! The only steel that doesn't contain atmospheric hangers-on is that which was produced before such an atmosphere exists.
This means large sources of steel that have been created before nuclear testing, and isolated from the atmosphere thereafter.
The prime candidate?
Shipwrecks!


## Low-silicon text
You can see where this is going.

There is a similar turning point going on, well, that has already happened.
[Large Language Models (LLMs)](https://en.wikipedia.org/wiki/Large_language_model) are the latest iteration of artificial intelligence.
These are large neural networks enough that generate humanlike text, often indistinguishable from human-generated text.

Thus, for any text generated after a certain date
([say, Nov 30 2022, when OpenAI introduced ChatGPT](https://openai.com/blog/chatgpt)), there is an uncertainty as to whether or not a human or a machine generated it.
Equally, there is a new quality attributed to text generated before this advent, a certainty that it is human-generated.
Why care about this? Well, if you're studying humans or machines, you'd likely want to be confident you're studying only those you're interested in.

Mirroring the plain text dichotomy, there's an amusing observation that GitHub's "Arctic Code Vault," designed for code to survive the apocalypse, is now also a repository of human-generated code.
If you're interested in analyzing code generated by humans, you can no longer be certain that any code released
[after March 29, 2022 (the release of GitHub Copilot)](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/), is generated solely by humans.


## So what?
I don't know!

A few things are certain though:

* LLMs are not going away.
* They're going to continue to chew up text online.
* This means they will start consuming LLM-generated text.
* It also means humans will start consuming LLM-generated text. Ouroboros.
